{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "##pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abalone:\n",
    "\n",
    "    def __init__(self, train_data = None, test_data = None):\n",
    "        try:\n",
    "            self.train_data = train_data\n",
    "            self.test_data = test_data            \n",
    "        except Exception as e:\n",
    "            print({'Error':1, 'Message':f'__init__ function failed due to {e}'})\n",
    "\n",
    "    def process(self):\n",
    "        train_prediction = None\n",
    "        try:\n",
    "            train_data, test_data = self.reading_data(self.train_data, self.test_data)\n",
    "            train_info, test_info = self.checking_infomation(train_data, test_data)\n",
    "            train_null, test_null = self.checking_null(train_data, test_data)\n",
    "            train_data_values, test_data_values = self.checking_value_counts(train_data, test_data)\n",
    "            train_data_duplicates, test_data_duplicates = self.checking_duplicates(train_data, test_data)\n",
    "            train_data_unique, test_data_unique = self.checking_unique(train_data, test_data)\n",
    "            train_data, test_data = self.dropping_unneccasary_columns(train_data, test_data)\n",
    "            train_data_columns, test_data_columns = self.checking_columns(train_data, test_data)\n",
    "            X_train, y_train, X_test = self.splitting_train_and_test_data(train_data, test_data)\n",
    "            train_categorical_cols, train_numerical_cols, test_categorical_cols, test_numerical_cols = self.splitting_categorical_and_numerical_columns(X_train, y_train, X_test)\n",
    "            sex_categories = self.categorical_values()\n",
    "            #train_categorical_cols, test_categorical_cols = self.converting_sex_column(train_categorical_cols, test_categorical_cols)\n",
    "            preprocessor = self.pipeline(train_categorical_cols, train_numerical_cols, test_categorical_cols, test_numerical_cols, sex_categories)\n",
    "            X_train_processed, X_test_processed = self.train_and_test_dataframe(X_train, X_test, preprocessor)\n",
    "            train_prediction = self.model_training(X_train_processed, X_test_processed, y_train, X_test)\n",
    "        except Exception as e:\n",
    "            print({'Error':2, 'Message':f'process function failed due to {e}'})\n",
    "        return train_prediction\n",
    "    \n",
    "    def reading_data(self, train_data_path, test_data_path):\n",
    "        try:\n",
    "            train_data = pd.read_csv(train_data_path)\n",
    "            test_data = pd.read_csv(test_data_path)\n",
    "        except Exception as e:\n",
    "            print({'Error':3, 'Message':f'reading_data function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def checking_infomation(self, train_data, test_data):\n",
    "        try:\n",
    "            train_info = train_data.info()\n",
    "            test_info = test_data.info()\n",
    "        except Exception as e:\n",
    "            print({'Error':4, 'Message':f'cheking_information function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_info, test_info\n",
    "    \n",
    "    def checking_null(self, train_data, test_data):\n",
    "        try:\n",
    "            train_null = train_data.isnull().sum()\n",
    "            test_null = test_data.isnull().sum()\n",
    "        except Exception as e:\n",
    "            print({'Error':5, 'Message':f'cheking_null function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_null, test_null\n",
    "    \n",
    "    def checking_value_counts(self, train_data, test_data):\n",
    "        try:\n",
    "            train_data_values = train_data.value_counts()\n",
    "            test_data_values = test_data.value_counts()\n",
    "        except Exception as e:\n",
    "            print({'Error':6, 'Message':f'cheking_value_counts function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data_values, test_data_values\n",
    "    \n",
    "    def checking_duplicates(self, train_data, test_data):\n",
    "        try:\n",
    "            train_data_duplicates = train_data.duplicated().sum()\n",
    "            test_data_duplicates = test_data.duplicated().sum()\n",
    "        except Exception as e:\n",
    "            print({'Error':7, 'Message':f'cheking_duplicates function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data_duplicates, test_data_duplicates\n",
    "    \n",
    "    def checking_unique(self, train_data, test_data):\n",
    "        try:\n",
    "            train_data_unique = [train_data[i].unique() for i in train_data.columns]\n",
    "            test_data_unique = [test_data[i].unique() for i in test_data.columns]\n",
    "\n",
    "        except Exception as e:\n",
    "            print({'Error':8, 'Message':f'checking_unique function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data_unique, test_data_unique\n",
    "    \n",
    "    def dropping_unneccasary_columns(self, train_data, test_data):\n",
    "        try:\n",
    "            train_data = train_data.drop(['id'], axis=1)\n",
    "            test_data = test_data.drop(['id'], axis=1)\n",
    "        except Exception as e:\n",
    "            print({'Error':9, 'Message':f'dropping_unneccasary_columns function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def checking_columns(self, train_data, test_data):\n",
    "        try:\n",
    "            train_data_columns = train_data.columns\n",
    "            test_data_columns = test_data.columns\n",
    "        except Exception as e:\n",
    "            print({'Error':10, 'Message':f'checking_columns function failed due to {e}'})\n",
    "            return None, None\n",
    "        return train_data_columns, test_data_columns\n",
    "\n",
    "    def splitting_train_and_test_data(self, train_data, test_data):\n",
    "        try:\n",
    "            X_train = train_data.drop(['Rings'], axis=1)\n",
    "            y_train = train_data['Rings']\n",
    "            X_test = test_data\n",
    "        except Exception as e:\n",
    "            print({'Error':11, 'Message':f'splitting_train_and_test_data function failed due to {e}'})\n",
    "            return None, None, None\n",
    "        return X_train, y_train, X_test\n",
    "    \n",
    "    def splitting_categorical_and_numerical_columns(self, X_train, y_train, X_test):\n",
    "        try:\n",
    "            train_categorical_cols = X_train.select_dtypes(include='O').columns\n",
    "            train_numerical_cols = X_train.select_dtypes(exclude='O').columns\n",
    "            test_categorical_cols = X_test.select_dtypes(include='O').columns\n",
    "            test_numerical_cols = X_test.select_dtypes(exclude='O').columns\n",
    "        except Exception as e:\n",
    "            print({'Error': 12, 'Message': f'splitting_categorical_and_numerical_columns function failed due to {e}'})\n",
    "            return None, None, None, None\n",
    "        return train_categorical_cols, train_numerical_cols, test_categorical_cols, test_numerical_cols\n",
    "\n",
    "    \n",
    "    def categorical_values(self):\n",
    "        try:\n",
    "            sex_categories = ['F', 'M', 'I']\n",
    "        except Exception as e:\n",
    "            print({'Error':13, 'Message':f'categorical_values function failed due to {e}'})\n",
    "            return None\n",
    "        return sex_categories\n",
    "    \n",
    "    '''def converting_sex_column(self, train_categorical_cols,test_categorical_cols):\n",
    "        try:\n",
    "            labelencoder = LabelEncoder()\n",
    "            train_categorical_cols['Sex'] = labelencoder.fit_transform(train_categorical_cols['Sex'])\n",
    "            test_categorical_cols['Sex'] = labelencoder.fit_transform(test_categorical_cols['Sex'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print({'Error':14, 'Message':f'categorical_values function failed due to {e}'})\n",
    "            return None\n",
    "        return train_categorical_cols, test_categorical_cols'''\n",
    "    \n",
    "    def pipeline(self, train_categorical_cols, train_numerical_cols, test_categorical_cols, test_numerical_cols, sex_categories):\n",
    "        try:\n",
    "            numerical_pipeline = Pipeline(\n",
    "                steps = [\n",
    "                    ('imputer', SimpleImputer(strategy='median')),\n",
    "                    ('scaling', StandardScaler(with_mean=False))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            categorical_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(categories=[sex_categories], handle_unknown='ignore'))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('train_numerical_pipeline', numerical_pipeline, train_numerical_cols),\n",
    "                ('train_categorical_pipeline', categorical_pipeline, train_categorical_cols),\n",
    "                ('test_numerical_pipeline', numerical_pipeline, test_numerical_cols),\n",
    "                ('test_categorical_pipeline', categorical_pipeline, test_categorical_cols)\n",
    "            ])\n",
    "\n",
    "        except Exception as e:\n",
    "            print({'Error':15, 'Message':f'pipeline function failed due to {e}'})\n",
    "            return None\n",
    "        return preprocessor\n",
    "    \n",
    "    def train_and_test_dataframe(self, X_train, X_test, preprocessor):\n",
    "        try:\n",
    "            X_train_processed = pd.DataFrame(preprocessor.fit_transform(X_train), columns=preprocessor.get_feature_names_out())\n",
    "            X_test_processed = pd.DataFrame(preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())\n",
    "        except Exception as e:\n",
    "            print({'Error':16, 'Message':f'train_and_test_dataframe function failed due to {e}'})\n",
    "            return None, None\n",
    "        return X_train_processed, X_test_processed\n",
    "\n",
    "    def evaluate_metrics(self, true, predicted):\n",
    "        try:\n",
    "            r2 = r2_score(true, predicted)\n",
    "            mae = mean_absolute_error(true, predicted)\n",
    "            mse = mean_squared_error(true, predicted)\n",
    "            #rmsle = np.sqrt(mean_squared_log_error(true, predicted))\n",
    "        except Exception as e:\n",
    "            print({'Error': 17, 'Message': f'evaluate_metrics function failed due to {e}'})\n",
    "            return None, None, None, None\n",
    "        return r2, mae, mse\n",
    "\n",
    "    def model_training(self, X_train_processed, X_test_processed, y_train, test_data):\n",
    "        try:\n",
    "            models = {\n",
    "                # 'Linear Regression': LinearRegression(),\n",
    "                # \"Lasso\": Lasso(),\n",
    "                # \"Ridge\": Ridge(),\n",
    "                # \"ElasticNet\": ElasticNet(),\n",
    "                'Random Forest': RandomForestRegressor(),\n",
    "                # 'Support Vector Machine': SVR(),\n",
    "                # 'Decision Tree': DecisionTreeRegressor(),\n",
    "                # 'Ada Boost': AdaBoostRegressor(),\n",
    "                # 'Gradient Boost': GradientBoostingRegressor()\n",
    "            }\n",
    "\n",
    "            trained_model_list = []\n",
    "            model_list = []\n",
    "            r2_list = []\n",
    "\n",
    "            # Define hyperparameter grids for each model\n",
    "            param_grids = {\n",
    "                # 'Linear Regression': {},\n",
    "                # 'Lasso': {'alpha': [0.1, 1, 10], 'max_iter': [1000, 2000], 'tol': [0.001, 0.0001]},\n",
    "                # 'Ridge': {'alpha': [0.1, 1, 10], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], 'max_iter': [1000, 2000]},\n",
    "                # 'ElasticNet': {'alpha': [0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9], 'max_iter': [1000, 2000], 'tol': [0.001, 0.0001]},\n",
    "                'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False], 'random_state': [42]},\n",
    "                # 'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},\n",
    "                # 'Decision Tree': {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'random_state': [42]},\n",
    "                # 'Ada Boost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'loss': ['linear', 'square', 'exponential']},\n",
    "                # 'Gradient Boost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'],'random_state': [42]}\n",
    "            }\n",
    "\n",
    "            # Perform Grid Search and hyperparameter tuning for each model\n",
    "            for model_name, model in models.items():\n",
    "                param_grid = param_grids.get(model_name, {})  # Get hyperparameter grid for the current model\n",
    "                if param_grid:\n",
    "                    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "                    grid_search.fit(X_train_processed, y_train)\n",
    "                    best_params = grid_search.best_params_\n",
    "                    ##\n",
    "                    models[model_name].set_params(**best_params)  # Update model with best hyperparameters\n",
    "                    ##\n",
    "                    #model.set_params(**best_params)  # Update model with best hyperparameters\n",
    "                    # Print best_params within the loop \n",
    "                    print(\"Best parameters for\", model_name, \":\", best_params)\n",
    "                else:\n",
    "                    # Print best_params for models without hyperparameter grid\n",
    "                    print(\"Best parameters for\", model_name, \":\", model.get_params())\n",
    "\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                model.fit(X_train_processed, y_train)\n",
    "\n",
    "                y_train_pred = model.predict(X_train_processed)\n",
    "                r2, mae, mse = self.evaluate_metrics(y_train, y_train_pred)\n",
    "\n",
    "                print(model_name)\n",
    "                model_list.append(model_name)\n",
    "\n",
    "                print(\"MODEL TRAINING PERFORMANCE\")\n",
    "                print(\"R2_SQUARE\", r2 * 100)\n",
    "                print(\"MAE:\", mae)\n",
    "                print(\"MAE:\", mse)\n",
    "\n",
    "                r2_list.append(r2)\n",
    "\n",
    "                y_test_pred = model.predict(X_test_processed)\n",
    "                #y_test_pred = y_test_pred.round()\n",
    "                print(y_test_pred)\n",
    "                print(\"-\" * 35)\n",
    "                print(\"\\n\")\n",
    "\n",
    "                result = pd.DataFrame()\n",
    "                test_data_id = pd.read_csv('test.csv')\n",
    "                result['id'] = test_data_id['id']\n",
    "                result['Rings'] = y_test_pred\n",
    "                result.to_csv(f'{model_name}submission.csv', index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print({'Error': 18, 'Message': f'model_training function failed due to {e}'})\n",
    "            return None\n",
    "        return y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90615 entries, 0 to 90614\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              90615 non-null  int64  \n",
      " 1   Sex             90615 non-null  object \n",
      " 2   Length          90615 non-null  float64\n",
      " 3   Diameter        90615 non-null  float64\n",
      " 4   Height          90615 non-null  float64\n",
      " 5   Whole weight    90615 non-null  float64\n",
      " 6   Whole weight.1  90615 non-null  float64\n",
      " 7   Whole weight.2  90615 non-null  float64\n",
      " 8   Shell weight    90615 non-null  float64\n",
      " 9   Rings           90615 non-null  int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 6.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60411 entries, 0 to 60410\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              60411 non-null  int64  \n",
      " 1   Sex             60411 non-null  object \n",
      " 2   Length          60411 non-null  float64\n",
      " 3   Diameter        60411 non-null  float64\n",
      " 4   Height          60411 non-null  float64\n",
      " 5   Whole weight    60411 non-null  float64\n",
      " 6   Whole weight.1  60411 non-null  float64\n",
      " 7   Whole weight.2  60411 non-null  float64\n",
      " 8   Shell weight    60411 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_data_path = 'train.csv'\n",
    "    test_data_path = 'test.csv'\n",
    "    y_train_pred = Abalone(train_data=train_data_path, test_data=test_data_path).process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.6602141 , 10.61715429,  4.27773277, ...,  7.14080708,\n",
       "        6.89723363,  7.52806395])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
